# -*- coding: utf-8 -*-
"""(4)LinearRegression_StochasticGradientDescent-Worldbank_USLifeExpectancyatBirth.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Wbhd8hXm8tC1PP1l3TOs4W336uGNZYgY

## **MLPP25 // Linear Regression as Machine Learning: Life Expectancy Over Time**

*Feb 13, 2025*

This notebook will go through an example of Linear Regression in a Machine Learning context using publicly available USA life expectancy at birth data.

---
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import plotly.express as px

# -- set matplotlib defaults, all style sheets: https://matplotlib.org/stable/gallery/style_sheets/style_sheets_reference.html

# pandas use matplotlib in the backend
# all the plotting functions in pandas are like wrappers around matplotlib.
# so we can set a style sheet for matplotlib and it will apply to pandas plotting
# we can use the above link to get access to all the types of interfaces/ background/ styles that can be used

#matplotlib.pyplot - pyplot is like the submodule within matplotlib.
plt.style.use("bmh")

# -- define plotly express defaults

# -- set the filename and read in the data
fname = "/content/drive/Shareddrives/mlpp25/data/worldbank/wb_us_leb.csv"
wbdat = pd.read_csv(fname)
wbdat

# -- plot the World Bank data
ax = wbdat.plot("year", "leb_us", kind="scatter", xlabel="birth year",
                ylabel="US life expectance at birth [yr]", #dont forget to incldue the units
                color="steelblue", s=40, figsize=(7, 4))

#This is the dot plot
#x-axis - year
#y-axis - life expectancy at birth
#scatter plot
#xlabel and ylabel given to the axes
#s=40 changing the size of the dots in the scatter plot
#figsize - changing the size of the figure.

"""Inferences:
- upward trend
- but not monotonously increasing, but there is upward trend in general
- now, we can choose the model to be applied - we can use linear model here, which is concluded based on the scatter plot.

- we need to plot the data to watch the trend, so that we can understand what model to be used to fit.

we want to fit a straight line to the data using *Stochastic Gradient
Descent*, so let's import it from `scikit-learn` (abbreviated as sklearn), #refer the scikit-learn website
"""

# -- import scikit-learn's Stochastic Gradient Descent regressor
from sklearn.linear_model import SGDRegressor

#SGDRegressors are like the ones that implement stochastic gradient descent.

# -- now, we need to initialize an SGD regression model
lm = SGDRegressor()

# its like creating an instance
# analogy == SGDRegressor:human :: lm:person1
# it can be considered an object. object has attributes and methods. attributes are values associated with the object and methods are the functions associated with the object.

# -- fit the model with the data
lm.fit(wbdat[["year"]], wbdat[["leb_us"]])

# (wbdat["year"]) - gives a column
# type(wbdat["year"]) - series
# type(wbdat[["year"]]) - dataframe of 1 column
# type(wbdat[["year", "leb_us"]]) - dataframe of 2 columns.

"""For `sklearn`, independent variables must be in a 2D shape with each independent variable in a column (we'll see why later).  Now let's use the fit to make the model "prediction" for each year,"""

lm.coef_
lm.intercept_
#the attributes with underscores - attributes that have been modified by the fitting process.

# -- "predict" the data
model = lm.predict(wbdat[["year"]]) #predict takes the x-values (year) and predicts the y values.

# -- add prediction back to the original DataFrame - wbdat
wbdat["model"] = model

# -- plot the data
ax = wbdat.plot("year", "leb_us", kind="scatter", xlabel="birth year",
                ylabel="US life expectance at birth [yr]",
                color="steelblue", label="WB data", s=40, figsize=(7, 4))

# -- add the model line to the plot
ax = wbdat.plot("year", "model", label="linear model", color="red", ax=ax) #ax=ax is like putting this line onto the plot above.

"""The raw model fit looks pretty bad...  This is because of a mismatch between the scale of the x and y data and the very low alpha parameter in the model.  We need to **"*standardize*"** the data to put the dimensions on equal footing.

standardizing the data
- rather than having your data like between 70 and 78, we can have it between -2 and 2. same with the birth year too.
- we want to transform our data into values that preserve the relationships between the columns, but have the values on more equal footing.


The formula to standardize each value is: 𝑧=(𝑥−𝜇)/𝜎

Where:

𝑧 = standardized value (also called the z-score)

𝑥 = original value

𝜇 = mean of the column

𝜎 = standard deviation of the column
"""

# -- standardize the data
wbdat["year_st"] = (wbdat["year"] - wbdat["year"].mean()) / wbdat["year"].std()
wbdat["leb_us_st"] = (wbdat["leb_us"] - wbdat["leb_us"].mean()) / wbdat["leb_us"].std()

# -- let's plot the standardized data to see how it worked (notice the limits of the axes now)
ax = wbdat.plot("year_st", "leb_us_st", kind="scatter",
                xlabel="birth year [standardized]",
                ylabel="US life expectance at birth [standardized]",
                color="steelblue", label="WB data", s=40, figsize=(7, 4))

# -- redefine the the SGD regression model to use with the standardized data
lm_st = SGDRegressor()

# -- fit the standardized data
lm_st.fit(wbdat[["year_st"]], wbdat[["leb_us_st"]])

# -- "predict" the standardized data
model_st = lm_st.predict(wbdat[["year_st"]])
wbdat["model_st"] = model_st

# -- plot the standardized data
ax = wbdat.plot("year_st", "leb_us_st", kind="scatter",
                xlabel="birth year [standardized]",
                ylabel="US life expectance at birth [standardized]",
                color="steelblue", label="WB data", s=40, figsize=(7, 4))

# -- add the model
ax = wbdat.plot("year_st", "model_st", label="linear model", color="red", ax=ax)

"""But this is against the **standardized** data.  Let's "un-standardize" the model so that it can be compared to the raw data,

To unstandardize a value (i.e., convert a standardized z-score back to the original value), you use the inverse of the standardization formula:

𝑥 = (𝑧*×)+𝜎

Where:

𝑥 = original value (what we’re calculating)

𝑧 = standardized value

𝜇 = mean of the original column

𝜎 = standard deviation of the original column
"""

# -- "un-standardize" the model
model =
wbdat["model"] =

# -- plot the final model

"""Let's calculate the mean squared error, MSE $ = \sum (data - model)^2 / N_{data}$,"""

# -- calculate MSE
mse =
print("MSE = {0:0.3}".format(mse))

"""The most common way to use MSE is to compare it to the variance in the raw data:"""

# -- calculate the ratio of MSE to variance
var =
print("MSE/var = {0:0.3}".format(mse / var))

"""Another common measure of goodness of fit (that also doesn't take into account uncertainty in a measurement) is $R^2$ or the *fraction of variance in the data that is explained by the model*,"""

# -- calculate R^2
r2 = 1 - np.var(wbdat["leb_us"] - wbdat["model"]) / np.var(wbdat["leb_us"])
print("R^2 = {0:0.2}".format(r2))

# -- import scikit-learn's R^2 function

# -- use sklearn function for R^2
r2 =
print("R^2 = {0:0.2}".format(r2))